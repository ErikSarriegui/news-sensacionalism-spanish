# ğŸ·ï¸ News Labeling Pipeline: Clickbait & Sensationalism

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-Batch_API-green?logo=openai&logoColor=white)](https://platform.openai.com/docs/guides/batch)
[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Dataset-yellow)](https://huggingface.co/datasets/eriksarriegui/news-sensacionalism-spanish)

> **Herramienta de etiquetado sintÃ©tico** utilizada para generar el dataset de detecciÃ³n de desinformaciÃ³n en noticias (Clickbait y Sensacionalismo). Proyecto desarrollado como parte del TFM del MÃ¡ster en Ciencia de Datos (UCM).

Este repositorio contiene el cÃ³digo necesario para procesar grandes volÃºmenes de noticias utilizando la **Batch API de OpenAI**, lo que permite reducir costes en un 50% y procesar millones de tokens de forma asÃ­ncrona.

---

## ğŸš€ CaracterÃ­sticas

* **âš¡ Eficiencia de Costes:** Script dedicado (`count_tokens.py`) para estimar el precio antes de lanzar el trabajo usando `tiktoken`.
* **ğŸ› ï¸ Salidas Estructuradas:** Uso de **Pydantic** para forzar respuestas JSON vÃ¡lidas (schemas definidos en `objects.py`).
* **ğŸ§  Prompts Especializados:** Criterios lingÃ¼Ã­sticos definidos para detectar *Curiosity Gap* (Clickbait) y *ManipulaciÃ³n Emocional* (Sensacionalismo).
* **ğŸ”„ Pipeline Completo:** Desde la ingesta de archivos `.parquet` hasta la descarga de resultados `.jsonl`.

## ğŸ“‚ Estructura del Proyecto

```bash
.
â”œâ”€â”€ labeling/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ create_job.py       # Sube el archivo y crea el Batch Job
â”‚   â”œâ”€â”€ download_output.py  # Consulta estado y descarga resultados
â”‚   â”œâ”€â”€ generate_file.py    # Convierte DataFrame a JSONL formato Batch
â”‚   â”œâ”€â”€ count_tokens.py     # Estima tokens y costes
â”‚   â”œâ”€â”€ objects.py          # DefiniciÃ³n de modelos Pydantic (Output Parsers)
â”‚   â””â”€â”€ prompts.py          # Prompts de sistema para los agentes
â”œâ”€â”€ .env.example            # Plantilla de variables de entorno
â”œâ”€â”€ requirements.txt        # Dependencias
â””â”€â”€ README.md
```

## ğŸ› ï¸ InstalaciÃ³n
1. **Clona el repositorio**:
```bash
git clone https://github.com/ErikSarriegui/news-sensacionalism-spanish
cd news-labeling-pipeline
```

2. **Instala las dependencias**:
```bash
pip install -r requirements.txt
```

## âš™ï¸ Uso del Pipeline
El proceso se divide en 4 pasos secuenciales. AsegÃºrate de tener un archivo .parquet con tus noticias como entrada.

1. **Generar archivo de Batch (`.jsonl`)**
Prepara los datos definiendo el modelo y el tipo de tarea (`clickbait` o `sensacionalism`):
```bash
python -m labeling.generate_file \
  --input_file "data/raw_news.parquet" \
  --output_file "batch_input.jsonl" \
  --type clickbait \
  --model "gpt-5-mini" \
  --text_column "texto"
```

2. **Analizar Costes (Opcional pero recomendado)**
Antes de enviar, calcula cuÃ¡ntos tokens consumirÃ¡ el proceso para evitar sorpresas. Ten en cuenta que esto solo tomarÃ¡ en cuenta el nÃºmero de tokens de entrada (input).
```bash
python -m labeling.count_tokens \
  --file "batch_input.jsonl" \
  --input_price 0.15 \
  --output_price 0.60
```

3. **Crear el Job en OpenAI**
Sube el archivo y lanza el proceso de etiquetado en la nube.
```bash
python -m labeling.create_job \
  --file "batch_input.jsonl" \
  --job_name "Etiquetado Clickbait V1"
```
> El script devolverÃ¡ un BATCH_ID (ej. batch_abc123). GuÃ¡rdalo.

4. **Descargar Resultados**
Una vez completado (puede tardar hasta 24h), descarga las etiquetas.
```bash
python -m labeling.download_output \
  --batch_id "batch_abc123..." \
  --output_file "resultados_etiquetados.jsonl"
```

## ğŸ§  MetodologÃ­a de Etiquetado
El sistema utiliza dos enfoques distintos definidos en `prompts.py`:

### ValidaciÃ³n
La calidad de los datos generados con este cÃ³digo ha sido validada comparando las etiquetas de `gpt-5-mini` contra un modelo superior (`gpt-5.2`) en un subset de control, obteniendo un Agreement Score del 96%.

## ğŸ”— Dataset
El dataset final generado con estas herramientas estÃ¡ disponible (con acceso restringido para evaluaciÃ³n acadÃ©mica) en Hugging Face:

ğŸ¤— [Ver Dataset en Hugging Face](https://huggingface.co/datasets/eriksarriegui/news-sensacionalism-spanish)

## ğŸ‘¥ Autores
* Erik Sarriegui
* JesÃºs Antonio MartÃ­nez
* Pablo Navarro
* Julen Neila
* Pedro Pablo Vicente
* Eduardo Corral

*Disclaimer: Este repositorio utiliza la API de OpenAI. AsegÃºrate de cumplir con sus polÃ­ticas de uso y recuerda que eres responsable de los costes generados por la ejecuciÃ³n de estos scripts.*
